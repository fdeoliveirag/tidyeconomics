[
  {
    "path": "posts/2021-03-29-explorando-o-sidra-com-tidyverse-parte-ii/",
    "title": "Explorando o SIDRA com tidyverse - Parte II",
    "description": "Usando a PNAD Contínua para ilustrar a trajetória recente do mercado de trabalho no Brasil e compará-la ao último período recessivo.",
    "author": [
      {
        "name": "Felipe O. Gonçalves",
        "url": {}
      }
    ],
    "date": "2021-04-01",
    "categories": [
      "SIDRA",
      "PNADC"
    ],
    "contents": "\n\nbody{\n  font-size: 14pt;\n}\nh1, h2, h3 {\n  text-align: left;\n}\ntd{font-size: 16px;}\ncode.r{font-size: 14px;}\npre{font-size: 12px;}\nAproveitando a derradeira divulgação dos dados da PNAD Contínua, esta postagem se dedica à visualização de indicadores centrais para a análise do mercado de trabalho brasileiro.\nEm particular, compara-se o desempenho atual com o período recessivo entre 2014 e 2016, tornando explícito o caráter sui generis da crise atual.\nPacotes\n\n\nlibrary(sidrar)     # importação via API\nlibrary(ggseas)     # gráfico sem sazonalidade\nlibrary(ggthemes)   # estética do gráfico\n#\nlibrary(tidyverse)\n\n\n\n\nDados\nO procedimento de importação dos dados será o mesmo da primeira postagem da série, porém aplicado à Tabela 6318 da PNADC/M.\nEscolhendo apenas a quantidade total de pessoas (em milhares) como variável, para todas as condições e trimestres móveis, a disposição dos blocos fica assim:\n\nEntão, obtém-se sua consequente expressão:\n\n\nt6318 <- \"/t/6318/n1/all/v/1641/p/all/c629/all\"\n\n\n\n E a partir dela os dados originais, diretamente da fonte para o R:\n\n\ndf_ibge <- sidrar::get_sidra(api = t6318)\n\nnames(df_ibge)\n\n\n\n\n [1] \"Nível Territorial (Código)\"                                             \n [2] \"Nível Territorial\"                                                      \n [3] \"Unidade de Medida (Código)\"                                             \n [4] \"Unidade de Medida\"                                                      \n [5] \"Valor\"                                                                  \n [6] \"Brasil (Código)\"                                                        \n [7] \"Brasil\"                                                                 \n [8] \"Variável (Código)\"                                                      \n [9] \"Variável\"                                                               \n[10] \"Trimestre Móvel (Código)\"                                               \n[11] \"Trimestre Móvel\"                                                        \n[12] \"Condição em relação à força de trabalho e condição de ocupação (Código)\"\n[13] \"Condição em relação à força de trabalho e condição de ocupação\"         \n\n\nManipulação\nBem como na Parte I, aqui também são necessárias apenas três colunas:\n\n\npnad <- df_ibge %>%\n  as_tibble() %>%\n  select(\n    date  = \"Trimestre Móvel (Código)\",\n    name  = \"Condição em relação à força de trabalho e condição de ocupação\",\n    value = \"Valor\"\n  )\n\nhead(pnad, 5)\n\n\n# A tibble: 5 x 3\n  date   name                            value\n  <chr>  <chr>                           <dbl>\n1 201203 Total                          155670\n2 201203 Força de trabalho               95191\n3 201203 Força de trabalho - ocupada     87632\n4 201203 Força de trabalho - desocupada   7559\n5 201203 Fora da força de trabalho       60479\n\nPorém, o ideal para esta postagem é modificar o padrão dos dados de “comprido” para “largo” com tidyr::pivot_wider(), fazendo com que cada categoria possua sua própria coluna (e cada data torne-se única): \n\n\npnad <- pnad %>%\n  pivot_wider(names_from = name, values_from = value) %>%\n  rename_with(~ c(\"pia\", \"pea\", \"ocup\", \"desocup\", \"pnea\"), -date)\n\ntail(pnad)\n\n\n# A tibble: 6 x 6\n  date      pia    pea  ocup desocup  pnea\n  <chr>   <dbl>  <dbl> <dbl>   <dbl> <dbl>\n1 202008 174600  95460 81666   13794 79141\n2 202009 175121  96556 82464   14092 78565\n3 202010 175555  98361 84301   14061 77193\n4 202011 176014  99601 85578   14023 76413\n5 202012 176362 100104 86179   13925 76258\n6 202101 176674 100297 86025   14272 76377\n\n Finalmente, chega-se ao que interessa para os gráficos:\n— Os trimestres móveis transformados em objeto de tempo com readr::parse_date(); — A população ocupada em milhões; — As taxas de desemprego e de participação na força de trabalho.\n\n\npnad <- pnad %>%\n  transmute(\n    date   = parse_date(date, format = \"%Y%m\"),\n    ocup   = ocup / 1000,\n    desemp = desocup / pea * 100,\n    partic = pea / pia * 100\n  )\n\nglimpse(pnad)\n\n\nRows: 107\nColumns: 4\n$ date   <date> 2012-03-01, 2012-04-01, 2012-05-01, 2012-06-01, 2012…\n$ ocup   <dbl> 87.632, 88.407, 88.863, 89.129, 89.181, 89.428, 89.63…\n$ desemp <dbl> 7.940877, 7.748897, 7.607690, 7.517510, 7.433933, 7.2…\n$ partic <dbl> 61.14923, 61.50632, 61.68484, 61.69382, 61.62181, 61.…\n\n\nVisualização\nOptando por um tema inspirado na The Economist para todos os gráficos:\n\n\ntheme_set(ggthemes::theme_economist())\n\n\n\nNo primeiro gráfico, tem-se a população ocupada de janeiro de 2019 a janeiro de 2021. Para ressaltar valores importantes, criou-se uma nova variável apenas com primeira, última, mínima e máxima do período. Além disso, detalhou-se melhor a escala de tempo:\n\n\npnad %>%\n  filter(date >= \"2019-01-01\") %>%\n  mutate(\n    txt = if_else(\n      ocup %in% c(first(ocup), last(ocup), min(ocup), max(ocup)),\n      ocup, NULL\n    )\n  ) %>%\n  ggplot(aes(x = date, y = ocup, label = txt)) +\n  geom_line() +\n  geom_text() +\n  scale_x_date(date_labels = \"%b %Y\")\n\n\n\n\n\n\nUma realidade que dá sentido ao segundo gráfico. Nele, procurou-se mostrar — com ggplot2::annotate() — a diferença entre a crise atual e o último período recessivo, que compreende dez trimestres (2014.Q3 a 2016.Q4) de acordo com o CODACE.\nA tática mais usada em R para plotar múltiplas séries sob um mesmo período é a combinação entre tidyr::pivot_longer() e ggplot2::facet_wrap(), resgatando o padrão “comprido” para as variáveis de interesse (no caso, as taxas).\nFinalmente, o pacote {ggseas} permitiu dessazonalizar as séries “on the fly” para plotagem. O método X-13 foi usado.\n\n\n# início e fim dos períodos recessivos\ncodace <- as.Date(c(\"2014-07-01\", \"2016-12-01\", \"2020-01-01\"))\n\npnad %>%\n  pivot_longer(c(desemp, partic)) %>%\n  ggplot(aes(x = date, y = value, color = name)) +\n  ggseas::stat_seas(geom = \"line\", frequency = 12, start = c(2012, 3)) +\n  annotate(\"rect\",\n           xmin  = codace[c(1, 3)], xmax  = c(codace[2], Inf),\n           ymin  = c(-Inf, -Inf),   ymax  = c(Inf, Inf),\n           alpha = .3) +\n  facet_wrap(~ name, ncol = 1, scales = \"free\")\n\n\n\n\n\n\n\n\n\n\n\n\nA oferta de trabalho, que se manteve praticamente inalterada em 2014-16, sofreu um baque de 5 pontos percentuais durante a pandemia (sendo 7 até agosto e 2 recuperados posteriormente).\nSem essa quebra na série, o desemprego estaria num patamar consideravelmente maior (mesmo partindo de uma taxa já elevada, de 11,2% em janeiro de 2020).\n###\n\n\n\n",
    "preview": "posts/2021-03-29-explorando-o-sidra-com-tidyverse-parte-ii/explorando-o-sidra-com-tidyverse-parte-ii_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-04-02T14:30:24-03:00",
    "input_file": "explorando-o-sidra-com-tidyverse-parte-ii.utf8.md",
    "preview_width": 1248,
    "preview_height": 864
  },
  {
    "path": "posts/2021-03-12-raca-clusters-de-renda-e-classificacao-de-bairros-no-r/",
    "title": "Raça, clusters de renda e classificação de bairros no R",
    "description": "Um algoritmo simples de machine learning sobre a relação entre raça e renda nas cidades brasileiras.",
    "author": [
      {
        "name": "Felipe O. Gonçalves",
        "url": {}
      }
    ],
    "date": "2021-03-12",
    "categories": [
      "Censo Demográfico"
    ],
    "contents": "\n\nbody{\n  font-size: 14pt;\n}\nh1, h2, h3 {\n  text-align: left;\n}\ntd{font-size: 16px;}\ncode.r{font-size: 14px;}\npre{font-size: 12px;}\nEsta postagem representa um esforço preliminar no sentido de testar a possibilidade de prever o nível de renda de um bairro brasileiro apenas com base em sua configuração racial.\nO caso analisado será a cidade de origem do autor: a antiga João Pessoa, que conta com 63 bairros registrados no IBGE até então. O algoritmo, todavia, é generalizável para qualquer cidade. Seu instrumental é dividido em duas partes:\nNa primeira (não supervisionada), uma clusterização k-means agrupa os bairros em três classes relativas de renda: alta, média e baixa;\nNa segunda (supervisionada), uma classificação logística não-binária prevê a qual cluster o bairro pertence dada sua proporção de indivíduos brancos.\nPacotes\n\n\nlibrary(geobr)      # mapa de bairros\nlibrary(janitor)    # limpeza de nomes\nlibrary(MASS)       # logit ordenado\n#\nlibrary(tidyverse)\n\n\n\n\nDados\nA matéria-prima da análise é a Tabela 3177 do Censo Demográfico 2010.\nApós sua importação, um trabalho razoável de limpeza — valores ausentes, concisão, renivelamento e reordenação de categorias — resulta num data frame que apresenta as diferentes combinações para os 63 bairros entre 5 grupos raciais e 8 grupos de renda. É possível baixá-lo neste repositório.\n\n\ndf_pop <- read_rds(\"censo_3177_pb.rds\")\n\n# ex. bairro mais populoso da cidade, população parda\nfilter(df_pop, bairro == \"Mangabeira\", racial == \"Parda\")\n\n\n# A tibble: 9 x 4\n  bairro     racial renda              valor\n  <chr>      <fct>  <fct>              <dbl>\n1 Mangabeira Parda  Até 1/2 SM          1656\n2 Mangabeira Parda  Mais de 1/2 a 1 SM  8345\n3 Mangabeira Parda  Mais de 1 a 2 SM    6439\n4 Mangabeira Parda  Mais de 2 a 3 SM    1738\n5 Mangabeira Parda  Mais de 3 a 5 SM    1195\n6 Mangabeira Parda  Mais de 5 a 10 SM    509\n7 Mangabeira Parda  Mais de 10 SM         68\n8 Mangabeira Parda  Sem rendimento     12430\n9 Mangabeira Parda  Total              32380\n\n\n\n\nE para garantir uma visualização espacial dos dados, os polígonos dos bairros podem ser importados através do excelente {geobr}:\n\n\nsf_bairros <- geobr::read_neighborhood(year = 2010) %>%\n  filter(code_muni == 2507507) %>%  # código de João Pessoa\n  select(name_neighborhood, geom)\n\n\n\n\nContexto\nUm panorama das combinações raça-renda para o agregado dos bairros é bastante elucidativo e, dado o escopo do blog, suficiente como justificativa:\n\n\ndf_pop %>%\n  # para cada combinação entre raça e estrato de renda...\n  group_by(racial, renda) %>%\n  # ...o agregado de todos os bairros; e para cada grupo racial...\n  summarize(valor = sum(valor)) %>%\n  # ...a proporção de cada estrato;\n  mutate(valor = valor / last(valor)) %>%\n  # formato largo (estratos de renda em colunas)\n  pivot_wider(names_from = renda, values_from = valor)\n\n\n\nRendimento mensal por grupo racial em João Pessoa (2010)\n\n\n\n\nAs frações da população branca ganhando de dois salários mínimos em diante são sempre — e gradativamente — maiores que as respectivas frações dos outros grupos raciais. Estas, por sua vez, somente decrescem na medida em que a renda aumenta. \nget_split()\nUma boa tática para lidar com as variáveis é cindir os dados para elas terem suas bases próprias, manipulá-las separadamente e depois reuni-las.\nEvitando repetição desnecessária, é possível construir com tidy evaluation uma função usando dplyr::enquo() para chamar as colunas dentro do pipe:\n\n\nget_split <- function(y, x) {\n  # variável\n  x <- enquo(x)\n  # data frame\n  y %>%\n    # indivíduos por bairro pertencendo a cada categoria da variável\n    group_by(bairro, !!x) %>%\n    summarize(valor = sum(valor), .groups = \"drop\") %>%\n    # categorias formando colunas\n    pivot_wider(names_from = !!x, values_from = valor) %>%\n    # limpando os nomes das colunas\n    janitor::clean_names()\n}\n\n\n\n\nProporção de brancos\nCom os dados raciais, precisa-se da medida quantitativa de branquitude dos bairros:\n\n\nbranq <- df_pop %>%\n  get_split(racial) %>%\n  summarize(bairro,\n            prop_branq = branca / total)\n\nglimpse(branq)\n\n\nRows: 63\nColumns: 2\n$ bairro     <chr> \"Aeroclube\", \"Água Fria\", \"Altiplano Cabo Branco\"…\n$ prop_branq <dbl> 0.6256013, 0.5011933, 0.5281250, 0.2883413, 0.339…\n\n\n\n# branquitude\nbranq %>%\n  ggplot(aes(x = prop_branq)) +\n  geom_histogram(aes(y = ..density..)) +\n  geom_density()\n\n\n\nDistribuição racial dos bairros de João Pessoa (2010)\n\n\n\n\nClusters de renda\nNo caso dos dados de renda, tem-se como medida a participação de cada estrato na população ocupada dos bairros:\n\n\nrendim <- df_pop %>%\n  get_split(renda) %>%\n  mutate(across(where(is.numeric), ~ .x / (total - sem_rendimento))) %>%\n  select(bairro, contains(\"_sm\"))\n\nglimpse(rendim)\n\n\nRows: 63\nColumns: 8\n$ bairro             <chr> \"Aeroclube\", \"Água Fria\", \"Altiplano Cabo…\n$ ate_1_2_sm         <dbl> 0.008200837, 0.011596548, 0.067423231, 0.…\n$ mais_de_1_2_a_1_sm <dbl> 0.1358996, 0.2014563, 0.2830441, 0.598030…\n$ mais_de_1_a_2_sm   <dbl> 0.2060251, 0.2758900, 0.1965955, 0.200843…\n$ mais_de_2_a_3_sm   <dbl> 0.12702929, 0.17637540, 0.09012016, 0.031…\n$ mais_de_3_a_5_sm   <dbl> 0.17456067, 0.18959008, 0.11014686, 0.019…\n$ mais_de_5_a_10_sm  <dbl> 0.213221757, 0.121089536, 0.143858478, 0.…\n$ mais_de_10_sm      <dbl> 0.1350627615, 0.0240021575, 0.1088117490,…\n\nSeja por silhueta ou cotovelo, o número ótimo de clusters varia entre dois e três. Para trabalhar com a ideia de classe média, optou-se pelo último:\n\n\nset.seed(321)  # ordem dos clusters preservada\n\nk_rendim <- rendim %>%\n  summarize(bairro,\n            cluster = select(., -bairro) %>%\n              kmeans(centers   = 3,\n                     nstart    = 10,\n                     algorithm = \"Hartigan-Wong\") %>%\n              pluck(\"cluster\") %>%\n              as_factor())\n\nglimpse(k_rendim)\n\n\nRows: 63\nColumns: 2\n$ bairro  <chr> \"Aeroclube\", \"Água Fria\", \"Altiplano Cabo Branco\", \"…\n$ cluster <fct> 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 2, 2, 2, 1, 1, 2, 1…\n\n\n\n# geografia\nk_rendim %>%\n  mutate(bairro = str_to_title(bairro)) %>%\n  inner_join(sf_ibge, by = c(\"bairro\" = \"name_neighborhood\")) %>%\n  ggplot(aes(geometry = geom, fill = cluster)) +\n  geom_sf()\n\n\n\nClusters dos bairros de João Pessoa por renda (2010)\n\nNota: O “buraco” no meio do mapa, na verdade, são mais de 500 hectares remanescentes de Mata Atlântica natural, que abrigam o Jardim Botânico da cidade.\n\n\n\n\nClassificação\nEstimando por logit ordenado:\n\n\npred_logit <- k_rendim %>%\n  inner_join(branq, by = \"bairro\") %>%\n  mutate(pred = (cluster ~ prop_branq) %>%\n           MASS::polr(method = \"logistic\") %>%\n           predict(),\n         acc  = (cluster == pred))\n\nglimpse(pred_logit)\n\n\nRows: 63\nColumns: 5\n$ bairro     <chr> \"Aeroclube\", \"Água Fria\", \"Altiplano Cabo Branco\"…\n$ cluster    <fct> 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 2, 2, 2, 1, 1, 2…\n$ prop_branq <dbl> 0.6256013, 0.5011933, 0.5281250, 0.2883413, 0.339…\n$ pred       <fct> 3, 2, 3, 1, 1, 3, 2, 2, 3, 3, 3, 2, 3, 1, 1, 1, 2…\n$ acc        <lgl> TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE…\n\nNa prática, o que acontece com esse modelo bivariado é simplesmente uma otimização da escolha de três intervalos de branquitude para o encaixe de cada cluster:\n\n\n# intervalos\npred_logit %>%\n  filter(acc == TRUE) %>%\n  group_by(cluster) %>%\n  summarize(min_prop_branq = min(prop_branq),\n            max_prop_branq = max(prop_branq))\n\n\n# A tibble: 3 x 3\n  cluster min_prop_branq max_prop_branq\n  <fct>            <dbl>          <dbl>\n1 1                0.284          0.377\n2 2                0.396          0.501\n3 3                0.517          0.699\n\nPorém, a dimensão racial da estrutura socioeconômica da cidade é tão forte que mesmo essa simplicidade é capaz de prever corretamente o nível de renda de 51 dos 63 bairros:\n\n\n# acurácia por grupos\npred_logit %>%\n  group_by(cluster) %>%\n  summarize(true        = sum(acc == TRUE),\n            false       = n() - true,\n            performance = true / n())\n\n\n# A tibble: 3 x 4\n  cluster  true false performance\n  <fct>   <int> <int>       <dbl>\n1 1          21     3       0.875\n2 2          12     6       0.667\n3 3          18     3       0.857\n\n# acurácia total\nsummarize(pred_logit, performance = sum(acc == TRUE) / n())\n\n\n# A tibble: 1 x 1\n  performance\n        <dbl>\n1       0.810\n\nLogo, ao separar os bairros de João Pessoa em três faixas de branquitude: i) de 28 a 38%; ii) de 39 a 50% e; iii) de 51 a 70% de brancos, torna-se possível classificar corretamente mais de 4/5 deles entre baixa, média e alta renda.\n\n\n# visualização final\npred_logit %>%\n  ggplot(aes(x = prop_branq, y = cluster)) +\n  geom_boxplot(aes(fill = cluster)) +\n  geom_jitter(aes(color = acc))\n\n\n\nBairros de João Pessoa: Raça vs. Renda (2010)\n\n\n\n\n\n\n\n###\n\n\n\n",
    "preview": "posts/2021-03-12-raca-clusters-de-renda-e-classificacao-de-bairros-no-r/explorando-o-sidra-com-tidyverse-parte-ii_files/figure-html5/unnamed-chunk-20-1.png",
    "last_modified": "2021-04-02T14:31:59-03:00",
    "input_file": "explorando-o-sidra-com-tidyverse-parte-ii.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-22-explorando-o-sidra-com-tidyverse-parte-i/",
    "title": "Explorando o SIDRA com tidyverse - Parte I",
    "description": "Usando a composição do IPCA para calcular e visualizar o padrão da inflação acumulada no Brasil em tempos de Covid.",
    "author": [
      {
        "name": "Felipe O. Gonçalves",
        "url": {}
      }
    ],
    "date": "2021-02-22",
    "categories": [
      "SIDRA",
      "IPCA"
    ],
    "contents": "\n\nbody{\n  font-size: 14pt;\n}\nh1, h2, h3 {\n  text-align: left;\n}\ntd{font-size: 16px;}\ncode.r{font-size: 14px;}\npre{font-size: 12px;}\nEste blog estreia com a primeira parte de uma sequência de postagens que procurará explorar as bases de dados do SIDRA através de uma abordagem avançada de workflow no R.\nNa postagem de hoje, calcula-se a variação mensal acumulada do IPCA desagregado em grupos para, em seguida, construir-se um gráfico sobre a inflação brasileira durante a pandemia – com atenção especial à inflação de alimentos. \nPacotes\n\n\nlibrary(sidrar)     # importação via API\nlibrary(ggthemes)   # estética do gráfico\n#\nlibrary(tidyverse)\n\n\n\n\nDados\nNão será preciso baixar nenhum arquivo. Seguindo os passos abaixo, encontra-se a expressão que permitirá levar os dados direto para o R:\nAcessar o portal do SIDRA\nIPCA > Relação de Tabelas > 7061\nDefinir opções:\nVariável: variação mensal (%)\nGeral, grupo, subgrupo, item e subitem: 9 componentes\nMês: mar/2020 a jan/2021\nUnidade Territorial: Brasil\n\nArrastar os blocos até ficarem dispostos assim:\n\nMenu Inferior Direito: Links de Compartilhar > Parâmetros para a API\n Feito. Cria-se então um objeto com a expressão (a partir de \"/t\"):\n\n\n\nt7061 <- \"/t/7061/n1/all/v/306/p/last%2011/c315/7170,7445,7486,7558,7625,7660,7712,7766,7786/d/v306%202\"\n\n\n\n\n E esse objeto é suficiente para importar os dados por meio do providencial {sidrar}:\n\n\ndf_ibge <- sidrar::get_sidra(api = t7061)\n\nnames(df_ibge)\n\n\n\n\n [1] \"Nível Territorial (Código)\"                     \n [2] \"Nível Territorial\"                              \n [3] \"Unidade de Medida (Código)\"                     \n [4] \"Unidade de Medida\"                              \n [5] \"Valor\"                                          \n [6] \"Brasil (Código)\"                                \n [7] \"Brasil\"                                         \n [8] \"Variável (Código)\"                              \n [9] \"Variável\"                                       \n[10] \"Mês (Código)\"                                   \n[11] \"Mês\"                                            \n[12] \"Geral, grupo, subgrupo, item e subitem (Código)\"\n[13] \"Geral, grupo, subgrupo, item e subitem\"         \n\n\nManipulação\nDas treze colunas, apenas três serão necessárias aqui:\n\n\nipca <- df_ibge %>%\n  as_tibble() %>%\n  select(\n    date          = \"Mês\",\n    component     = \"Geral, grupo, subgrupo, item e subitem\",\n    mth_inflation = \"Valor\"\n  )\n\nhead(ipca, 9)\n\n\n# A tibble: 9 x 3\n  date       component                   mth_inflation\n  <chr>      <chr>                               <dbl>\n1 março 2020 1.Alimentação e bebidas              0.84\n2 março 2020 2.Habitação                          0.13\n3 março 2020 3.Artigos de residência             -1.08\n4 março 2020 4.Vestuário                          0.21\n5 março 2020 5.Transportes                       -0.9 \n6 março 2020 6.Saúde e cuidados pessoais          0.21\n7 março 2020 7.Despesas pessoais                 -0.23\n8 março 2020 8.Educação                           0.59\n9 março 2020 9.Comunicação                        0.04\n\nOs dados vêm num padrão “comprido” ao invés de “largo”: não há uma coluna para cada componente, e isso faz com que se tenha nove observações para cada mês. Diante da finalidade desta postagem, o ideal será mantê-los assim.\n O cálculo da inflação acumulada para \\(t \\in \\{1,\\ ..., 11\\}\\) meses de pandemia é recursivo (depende dos próprios valores defasados). De uma variação mensal inicial \\(\\pi_1^{ac} = \\pi_1\\), tem-se\n\\[\\pi_t^{ac} = (1\\ +\\ \\frac{\\pi_t}{100})\\ \\times\\ \\pi_{t-1}^{ac}\\ +\\ \\pi_t\\ \\]\npara \\(t\\neq1\\). Essa atribuição requer a função purrr::accumulate() para ser realizada dentro do flow — em parceria com dplyr::group_by() para ser aplicada a cada componente em separado:\n\n\nipca <- ipca %>%\n  group_by(component) %>%          # agrupamento\n  mutate(\n    # .y\n    accum_inflation = accumulate(\n      mth_inflation,               # .x\n      ~ (1 + .x / 100) * .y + .x   # atribuição recursiva de .y\n    )\n  )\n\n\n\n Conferindo o primeiro e mais relevante componente do período:\n\n\nhead(arrange(ipca, component), 11)\n\n\n# A tibble: 11 x 4\n# Groups:   component [1]\n   date          component               mth_inflation accum_inflation\n   <chr>         <chr>                           <dbl>           <dbl>\n 1 março 2020    1.Alimentação e bebidas          0.84            0.84\n 2 abril 2020    1.Alimentação e bebidas          1.57            2.42\n 3 maio 2020     1.Alimentação e bebidas          0.33            2.76\n 4 junho 2020    1.Alimentação e bebidas          0.64            3.42\n 5 julho 2020    1.Alimentação e bebidas          0.42            3.85\n 6 agosto 2020   1.Alimentação e bebidas          1.17            5.07\n 7 setembro 2020 1.Alimentação e bebidas          2.54            7.74\n 8 outubro 2020  1.Alimentação e bebidas          1.9             9.78\n 9 novembro 2020 1.Alimentação e bebidas          2.28           12.3 \n10 dezembro 2020 1.Alimentação e bebidas          1.37           13.8 \n11 janeiro 2021  1.Alimentação e bebidas          0.68           14.6 \n\n Agora, chega-se ao valor acumulado no final do período para todos os componentes:\n\n\n# jan/2021\nipca <- summarize(ipca, accum_inflation = last(accum_inflation))\n\n\n\n E eis a matéria-prima do gráfico:\n\n\narrange(ipca, desc(accum_inflation))\n\n\n# A tibble: 9 x 2\n  component                   accum_inflation\n  <chr>                                 <dbl>\n1 1.Alimentação e bebidas             14.6   \n2 3.Artigos de residência              7.07  \n3 2.Habitação                          3.98  \n4 9.Comunicação                        3.11  \n5 6.Saúde e cuidados pessoais          1.41  \n6 5.Transportes                        1.36  \n7 7.Despesas pessoais                  0.749 \n8 4.Vestuário                          0.0240\n9 8.Educação                          -2.50  \n\nNota: Ao olhar para a deflação dos serviços educacionais, deve-se ter em conta que fevereiro, um mês particularmente importante para o componente, é o único que não se faz presente nos dados. \nVisualização\nO primeiro passo para o sucesso do gráfico de barras será, seguindo o embalo da formatação, reordenar a sequência de componentes com forcats::fct_reorder() de acordo com o tamanho da inflação acumulada:\n\n\nipca <- ipca %>%\n  mutate(\n    component = component %>%\n      # retirada de numeração\n      str_sub(3) %>%\n      # concisão\n      recode(\"Alimentação e bebidas\"     = \"Alimentação\",\n             \"Artigos de residência\"     = \"Residência\",\n             \"Saúde e cuidados pessoais\" = \"Saúde\",\n             \"Despesas pessoais\"         = \"Desp. Pessoais\") %>%\n      # critério de ordenação\n      fct_reorder(accum_inflation)\n  )\n\n\n\n A carcaça do gráfico já pode ser criada:\n\n\nipca %>%\n  ggplot(aes(accum_inflation, component)) +\n  geom_col()\n\n\n\n\nPorém ela é pouco apelativa (apesar de ter seu charme). O segundo passo será desfrutar das possibilidades de montagem em cima dessa carcaça — por exemplo, a função ggplot2::geom_label(). Esmiuçá-las exigiria uma postagem à parte.\nPor último, escolhe-se tema e paleta de cores a gosto. Como a inspiração para esta postagem veio justamente de matérias jornalísticas sobre a trajetória recente da inflação de alimentos, foi escolhido um padrão do Wall Street Journal encontrado no {ggthemes}:\n\n\n\nUm senhor ganho de apelo estético.\nNa segunda parte da sequência, será possível trabalhar com planilhas mais complexas do SIDRA. \n###\n\n\n\n",
    "preview": "posts/2021-02-22-explorando-o-sidra-com-tidyverse-parte-i/desmistificando-o-sidra-parte-i_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-04-01T10:42:41-03:00",
    "input_file": "desmistificando-o-sidra-parte-i.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]
